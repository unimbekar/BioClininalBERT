# README.md

## ğŸ§¬ Biomedical Multi-label Classification with Bio_ClinicalBERT

This project fine-tunes Bio_ClinicalBERT for multi-label classification of unstructured medical notes using NLP-based weak supervision.

---

### ğŸ” Use Case
Automatically tag medical narratives (clinical notes, encounter summaries, etc.) with relevant health indicators (e.g., `diabetes`, `mental_health`) using domain-specific transformers.

---

### ğŸ§ª Features
- **Bio_ClinicalBERT** fine-tuning for real-time inference.
- **Zero-shot classification** to label data using `facebook/bart-large-mnli`.
- Modular code with unit tests.

---

### ğŸ“ Project Structure
```
bioclinicalbert_project/
â”œâ”€â”€ README.md
â”œâ”€â”€ data/
â”‚   â””â”€â”€ clinical_notes.csv            # Input CSV with a 'text' column
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                     # Configuration: labels, thresholds, models
â”‚   â”œâ”€â”€ preprocess.py                 # Cleans and loads the data
â”‚   â”œâ”€â”€ zero_shot_labeler.py         # Zero-shot NLP labeling pipeline
â”‚   â”œâ”€â”€ dataset.py                   # PyTorch dataset wrapper
â”‚   â”œâ”€â”€ trainer.py                   # Fine-tunes Bio_ClinicalBERT
â”‚   â””â”€â”€ main.py                      # End-to-end runner
â””â”€â”€ tests/
    â”œâ”€â”€ test_preprocess.py
    â”œâ”€â”€ test_labeling.py
    â””â”€â”€ test_training.py
```

---

### âš™ï¸ Setup
```bash
pip install transformers datasets scikit-learn sentence-transformers
```

---

### ğŸš€ Run Pipeline
```bash
cd bioclinicalbert_project
python src/main.py
```

Make sure your data file `clinical_notes.csv` is in the `data/` folder and includes a `text` column.

---

### ğŸ§ª Run Tests
```bash
pytest tests/
```

---

### ğŸ§  Notes
- **Labeling Strategy**: Zero-shot classification from `facebook/bart-large-mnli` is used to weakly annotate the dataset.
- **Fine-tuning Model**: `Bio_ClinicalBERT` (by Emily Alsentzer).
- **Multi-label Output**: Trained using sigmoid activation and binary cross-entropy.

---

### ğŸ“Œ Future Work
- Use contrastive learning or sentence embeddings for self-supervised pre-labeling.
- Evaluate performance across clinical subtypes (e.g., discharge summaries vs. intake).

---

### ğŸ§‘â€âš•ï¸ Authors
Created for real-world healthcare NLP applications where labeled data is scarce but unstructured notes are abundant.

---

### ğŸ“„ License
MIT License
